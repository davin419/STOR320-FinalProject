---
title: "R Notebook"
output: html_notebook
---

```{r}
library(readr)
library(tidyverse)
library(ggplot2)
library(leaps)
library(modelr)

source("https://raw.githubusercontent.com/JA-McLean/STOR455/master/scripts/ShowSubsets.R")
```

```{r}
CBB = read_csv("cbb.csv")
CBB <- CBB %>% 
  rename(School=TEAM) %>% 
  rename(Conference=CONF) %>% 
  rename(GamesPlayed = G) %>% 
  rename(GamesWon = W) %>% 
  rename(AdjustedOffensiveEfficiency=ADJOE) %>% 
  rename(AdjustedDefensiveEfficiency=ADJDE) %>% 
  rename(PowerRating = BARTHAG) %>% 
  rename(EffectiveFieldGoalPercentageShot=EFG_O) %>% 
  rename(EffectiveFieldGoalPercentageAllowed=EFG_D) %>% 
  rename(TurnoverRate=TOR) %>% 
  rename(StealRate=TORD) %>% 
  rename(OffensiveReboundRate=ORB) %>% 
  rename(OffensiveReboundRateAllowed=DRB) %>% 
  rename(FreeThrowRate=FTR) %>%
  rename(FreeThrowRateAllowed = FTRD) %>% 
  rename(TwoPointShootingPercentage = "2P_O") %>% 
  rename(TwoPointShootingPercentageAllowed='2P_D') %>% 
  rename(ThreePointShootingPercentage='3P_O') %>% 
  rename(ThreePointShootingPercentageAllowed='3P_D') %>% 
  rename(AdjustedTempo=ADJ_T) %>% 
  rename(WinsAboveBubble=WAB) %>% 
  rename(Postseason=POSTSEASON) %>% 
  rename(Seed=SEED) %>% 
  rename(Season=YEAR)
```

```{r}
q1 <- filter(CBB, !is.na(Postseason)) %>% 
  mutate(WinningPercentage = GamesWon / GamesPlayed)

q1$Postseason[q1$Postseason == "Champions"] <- 8
q1$Postseason[q1$Postseason == "2ND"] <- 7
q1$Postseason[q1$Postseason == "F4"] <- 6
q1$Postseason[q1$Postseason == "E8"] <- 5
q1$Postseason[q1$Postseason == "S16"] <- 4
q1$Postseason[q1$Postseason == "R32"] <- 3
q1$Postseason[q1$Postseason == "R64"] <- 2
q1$Postseason[q1$Postseason == "R68"] <- 1

q1$Postseason = as.integer(as.numeric(q1$Postseason))
q1$Seed = as.integer(q1$Seed)
```


```{r}
# All subsets method
q1.min = select(q1, c(7:23,25),-20) # Get rid of non-numerical variables and AOE, ADE, Adjusted Tempo

all.mod = regsubsets(Postseason~., data=q1.min, nbest=1)
all.mod.result = ShowSubsets(all.mod)
all.mod.result[order(all.mod.result$Cp),]
```

```{r}
# Separate into train/test sets with 80% to 20% ratio
q1.2 = q1 %>%
        mutate(Set=sample(x=c("Train", "Test"), size=476, replace=TRUE, prob=c(.8,.2)))

train.q1<-filter(q1.2,Set=="Train")
test.q1<-filter(q1.2,Set=="Test")
```

```{r}
#Use models with training set
lm1 = lm(Postseason~EffectiveFieldGoalPercentageAllowed +
        OffensiveReboundRateAllowed +
        FreeThrowRate +
        FreeThrowRateAllowed +
        TwoPointShootingPercentageAllowed +
        ThreePointShootingPercentageAllowed +
        Seed +
        WinningPercentage, data=train.q1)

lm2 = lm(Postseason~OffensiveReboundRateAllowed + FreeThrowRateAllowed + Seed + WinningPercentage, data=train.q1)
lm3 = lm(Postseason~OffensiveReboundRateAllowed + FreeThrowRate + FreeThrowRateAllowed + Seed + WinningPercentage,
         data=train.q1)
```

```{r}
test.q1 = test.q1 %>% 
      add_predictions(lm1, var="LinMod1") %>%
      add_predictions(lm2, var="LinMod2") %>%
      add_predictions(lm3, var="LinMod3") %>%
      add_residuals(lm1, var="LinRes1") %>%
      add_residuals(lm2, var="LinRes2") %>%
      add_residuals(lm3, var="LinRes3")
```

```{r}
plot(lm1)
```

```{r}
compare.models <- test.q1 %>% 
  gather(27:29, key="Model", value="ModelPrediction", factor_key=T)

compare.models <- compare.models %>% 
  gather(27:29, key="Residual", value="ResidualPrediction", factor_key=T)
```

```{r}
# Actual vs. fitted with all 3 models. The line represents a perfect fit.
ggplot(compare.models, aes(x=Postseason, y=ModelPrediction, color=Model)) +
  geom_point() + geom_smooth(method="lm") +
  geom_abline(slope=1, intercept=0, size=1) +
  xlab("Actual Postseason Status") + ylab("Fitted Postseason Status") +
  theme_minimal()
```

```{r}
# functions
MAE.func <- function(actual, predict) {
  return (mean(abs(actual-predict)))
}

mae1 = MAE.func(test.q1$Postseason, test.q1$LinMod1)
mae2 = MAE.func(test.q1$Postseason, test.q1$LinMod2)
mae3 = MAE.func(test.q1$Postseason, test.q1$LinMod3)

compare.mae <- c(mae1, mae2, mae3)
highest.mae <- which.max(compare.mae)
# Highest MAE is LinMod3

lowest.mae <- which.min(compare.mae)
# Lowest MAE is LinMod1

compare.mae[highest.mae] - compare.mae[lowest.mae]
# LinMod1 has 8 predictors, LinMod2 has 4, and LinMod3 has 5. The difference between the models is so small, so the added predictors in LinMod1 probably aren't doing much. Since they're all so close, we might as well just look at LinMod2 since it has the least number of predictors
```

```{r}
# Blue line is actual slope, red line is a perfect slope if the predictions were perfect.
ggplot(test.q1, aes(x=Postseason, y=LinMod1)) +
  geom_point() + geom_smooth(method="lm") +
  xlab("Actual Postseason Status") + ylab("Fitted Postseason Status") +
  geom_abline(slope=1, intercept=0, color="red", size=1) +
  theme_minimal()
```

```{r}
# Blue line is the slope of the residuals and red line is a perfect line where the residuals are 100% random. All the residuals look pretty normal.
# Plot the residuals against every predictor 

ggplot(test.q1, aes(x=OffensiveReboundRateAllowed, y=LinRes1)) +
  geom_point() + geom_smooth(method="lm") +
  geom_hline(yintercept=0, color="red", size=1) +
  xlab("Offensive Rebound Rate Allowed") + ylab("Residual") +
  theme_minimal()

ggplot(test.q1, aes(x=FreeThrowRateAllowed, y=LinRes1)) +
  geom_point() + geom_smooth(method="lm") +
  geom_hline(yintercept=0, color="red", size=1) +
  xlab("Free Throw Rate Allowed") + ylab("Residual") +
  theme_minimal()

ggplot(test.q1, aes(x=Seed, y=LinRes1)) +
  geom_point() + geom_smooth(method="lm") +
  geom_hline(yintercept=0, color="red", size=1) +
  xlab("Seed") + ylab("Residual") +
  theme_minimal()

ggplot(test.q1, aes(x=WinningPercentage, y=LinRes1)) +
  geom_point() + geom_smooth(method="lm") +
  geom_hline(yintercept=0, color="red", size=1) +
  xlab("Winning Percentage") + ylab("Residual") +
  theme_minimal()
```

